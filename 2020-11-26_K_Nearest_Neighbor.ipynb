{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<iris Data>\n",
      "The number of sample data:150\n",
      "The number of features of the data:4\n",
      "labels of the data:[0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns = iris.feature_names)\n",
    "print('<iris Data>')\n",
    "print('The number of sample data:'+str(len(df)))\n",
    "print('The number of features of the data:'+str(len(df.columns)))\n",
    "print('labels of the data:'+str(np.unique(y)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train data set : 100\n",
      "The number of test data set : 50\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33,\n",
    "                                                   random_state = 42)\n",
    "print('The number of train data set : %d' %len(X_train))\n",
    "print('The number of test data set : %d' %len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KNeighborsClassifier(n_neighbors = 3)\n",
    "estimator.fit(X_train, y_train)\n",
    "label_predict = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of classification:  0.980000\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy score of classification: %9f'\n",
    "     %accuracy_score(y_test, label_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import normalize\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "df = pd.DataFrame(X, columns = breast_cancer.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train data set : 381\n",
      "The number of test data set : 188\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33,\n",
    "                                                   random_state = 42)\n",
    "print('The number of train data set : %d' %len(X_train))\n",
    "print('The number of test data set : %d' %len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of classification 0.941489362\n"
     ]
    }
   ],
   "source": [
    "estimator = KNeighborsClassifier(n_neighbors = 5, weights = 'distance')\n",
    "estimator.fit(X_train, y_train)\n",
    "label_predict = estimator.predict(X_test)\n",
    "print('The accuracy score of classification %.9f'\n",
    "     %accuracy_score(y_test, label_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99]\n",
      "The number of neighbors k is 50\n"
     ]
    }
   ],
   "source": [
    "myList = list(range(1,100))\n",
    "neighbors = [x for x in myList if x%2 !=0]\n",
    "print(neighbors)\n",
    "print('The number of neighbors k is %d' %len(neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<k = 1>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.92105263 0.97368421 0.81578947 0.89473684\n",
      " 0.89473684 0.89473684 0.89473684 0.84210526]\n",
      "The average score of scores is 0.894804318 \n",
      "\n",
      "<k = 3>\n",
      "The scores of classification are \n",
      "[0.94871795 0.86842105 0.89473684 0.94736842 0.94736842 0.89473684\n",
      " 0.86842105 0.89473684 0.94736842 0.81578947]\n",
      "The average score of scores is 0.902766532 \n",
      "\n",
      "<k = 5>\n",
      "The scores of classification are \n",
      "[0.94871795 0.86842105 0.89473684 0.94736842 0.94736842 0.92105263\n",
      " 0.94736842 0.86842105 0.92105263 0.81578947]\n",
      "The average score of scores is 0.908029690 \n",
      "\n",
      "<k = 7>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.89473684 0.94736842 0.94736842 0.92105263\n",
      " 0.92105263 0.86842105 0.92105263 0.84210526]\n",
      "The average score of scores is 0.907962213 \n",
      "\n",
      "<k = 9>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.94736842 0.92105263 0.92105263\n",
      " 0.94736842 0.86842105 0.89473684 0.81578947]\n",
      "The average score of scores is 0.900067476 \n",
      "\n",
      "<k = 11>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.94736842 0.92105263 0.92105263\n",
      " 0.94736842 0.86842105 0.94736842 0.81578947]\n",
      "The average score of scores is 0.905330634 \n",
      "\n",
      "<k = 13>\n",
      "The scores of classification are \n",
      "[0.97435897 0.81578947 0.86842105 0.97368421 0.94736842 0.97368421\n",
      " 0.92105263 0.86842105 0.94736842 0.81578947]\n",
      "The average score of scores is 0.910593792 \n",
      "\n",
      "<k = 15>\n",
      "The scores of classification are \n",
      "[0.97435897 0.81578947 0.86842105 0.97368421 0.97368421 0.92105263\n",
      " 0.92105263 0.84210526 0.94736842 0.81578947]\n",
      "The average score of scores is 0.905330634 \n",
      "\n",
      "<k = 17>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.94736842 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.94736842 0.81578947]\n",
      "The average score of scores is 0.902699055 \n",
      "\n",
      "<k = 19>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.94736842 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.94736842 0.81578947]\n",
      "The average score of scores is 0.902699055 \n",
      "\n",
      "<k = 21>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.94736842 0.81578947]\n",
      "The average score of scores is 0.905330634 \n",
      "\n",
      "<k = 23>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.94736842 0.81578947]\n",
      "The average score of scores is 0.905330634 \n",
      "\n",
      "<k = 25>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.94736842 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.94736842 0.81578947]\n",
      "The average score of scores is 0.902699055 \n",
      "\n",
      "<k = 27>\n",
      "The scores of classification are \n",
      "[0.94871795 0.84210526 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.94736842 0.81578947]\n",
      "The average score of scores is 0.902766532 \n",
      "\n",
      "<k = 29>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.97368421 0.94736842 0.89473684\n",
      " 0.92105263 0.84210526 0.94736842 0.81578947]\n",
      "The average score of scores is 0.902699055 \n",
      "\n",
      "<k = 31>\n",
      "The scores of classification are \n",
      "[0.97435897 0.81578947 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.94736842 0.81578947]\n",
      "The average score of scores is 0.902699055 \n",
      "\n",
      "<k = 33>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.92105263 0.81578947]\n",
      "The average score of scores is 0.902699055 \n",
      "\n",
      "<k = 35>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.92105263 0.81578947]\n",
      "The average score of scores is 0.902699055 \n",
      "\n",
      "<k = 37>\n",
      "The scores of classification are \n",
      "[0.97435897 0.84210526 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.92105263 0.81578947]\n",
      "The average score of scores is 0.902699055 \n",
      "\n",
      "<k = 39>\n",
      "The scores of classification are \n",
      "[0.94871795 0.81578947 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.92105263 0.81578947]\n",
      "The average score of scores is 0.897503374 \n",
      "\n",
      "<k = 41>\n",
      "The scores of classification are \n",
      "[0.92307692 0.86842105 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.84210526 0.92105263 0.81578947]\n",
      "The average score of scores is 0.900202429 \n",
      "\n",
      "<k = 43>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.894939271 \n",
      "\n",
      "<k = 45>\n",
      "The scores of classification are \n",
      "[0.92307692 0.81578947 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.892307692 \n",
      "\n",
      "<k = 47>\n",
      "The scores of classification are \n",
      "[0.92307692 0.78947368 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n",
      "<k = 49>\n",
      "The scores of classification are \n",
      "[0.92307692 0.81578947 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.892307692 \n",
      "\n",
      "<k = 51>\n",
      "The scores of classification are \n",
      "[0.92307692 0.78947368 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n",
      "<k = 53>\n",
      "The scores of classification are \n",
      "[0.92307692 0.78947368 0.86842105 0.97368421 0.97368421 0.89473684\n",
      " 0.92105263 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.887044534 \n",
      "\n",
      "<k = 55>\n",
      "The scores of classification are \n",
      "[0.92307692 0.78947368 0.86842105 0.97368421 0.94736842 0.89473684\n",
      " 0.92105263 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.887044534 \n",
      "\n",
      "<k = 57>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.89473684\n",
      " 0.92105263 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.892307692 \n",
      "\n",
      "<k = 59>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.89473684\n",
      " 0.92105263 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.892307692 \n",
      "\n",
      "<k = 61>\n",
      "The scores of classification are \n",
      "[0.92307692 0.81578947 0.86842105 0.97368421 0.94736842 0.89473684\n",
      " 0.89473684 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.884412955 \n",
      "\n",
      "<k = 63>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.89473684\n",
      " 0.89473684 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n",
      "<k = 65>\n",
      "The scores of classification are \n",
      "[0.92307692 0.86842105 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.89473684 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.892307692 \n",
      "\n",
      "<k = 67>\n",
      "The scores of classification are \n",
      "[0.92307692 0.86842105 0.86842105 0.97368421 0.97368421 0.92105263\n",
      " 0.89473684 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.894939271 \n",
      "\n",
      "<k = 69>\n",
      "The scores of classification are \n",
      "[0.92307692 0.86842105 0.86842105 0.97368421 0.94736842 0.89473684\n",
      " 0.89473684 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n",
      "<k = 71>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.89473684 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n",
      "<k = 73>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.89473684 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n",
      "<k = 75>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.89473684 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n",
      "<k = 77>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.89473684 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n",
      "<k = 79>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.97368421 0.94736842\n",
      " 0.89473684 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.894939271 \n",
      "\n",
      "<k = 81>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.97368421 0.92105263\n",
      " 0.89473684 0.81578947 0.89473684 0.81578947]\n",
      "The average score of scores is 0.892307692 \n",
      "\n",
      "<k = 83>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.97368421 0.94736842\n",
      " 0.86842105 0.78947368 0.89473684 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n",
      "<k = 85>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.86842105 0.78947368 0.89473684 0.81578947]\n",
      "The average score of scores is 0.884412955 \n",
      "\n",
      "<k = 87>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.94736842\n",
      " 0.86842105 0.78947368 0.89473684 0.81578947]\n",
      "The average score of scores is 0.887044534 \n",
      "\n",
      "<k = 89>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.86842105 0.78947368 0.89473684 0.81578947]\n",
      "The average score of scores is 0.884412955 \n",
      "\n",
      "<k = 91>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.86842105 0.78947368 0.92105263 0.81578947]\n",
      "The average score of scores is 0.887044534 \n",
      "\n",
      "<k = 93>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.86842105 0.78947368 0.89473684 0.81578947]\n",
      "The average score of scores is 0.884412955 \n",
      "\n",
      "<k = 95>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.86842105 0.78947368 0.92105263 0.81578947]\n",
      "The average score of scores is 0.887044534 \n",
      "\n",
      "<k = 97>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.86842105 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n",
      "<k = 99>\n",
      "The scores of classification are \n",
      "[0.92307692 0.84210526 0.86842105 0.97368421 0.94736842 0.92105263\n",
      " 0.86842105 0.81578947 0.92105263 0.81578947]\n",
      "The average score of scores is 0.889676113 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_scores=[]\n",
    "for k in neighbors:\n",
    "    print('<k = %d>'%k)\n",
    "    estimator = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(estimator, X_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "    print('The scores of classification are \\n'+ str(scores))\n",
    "    cv_scores.append(scores.mean())\n",
    "    print('The average score of scores is %.9f \\n'%scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors i is 13\n"
     ]
    }
   ],
   "source": [
    "MSE=[1-x for x in cv_scores]\n",
    "\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()\n",
    "\n",
    "min_MSE = min(MSE)\n",
    "index_of_min_MSE = MSE.index(min_MSE)\n",
    "optimal_k = neighbors[index_of_min_MSE]\n",
    "print('The optimal number of neighbors i is %d'%optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of classification: 0.962765957\n"
     ]
    }
   ],
   "source": [
    "estimator=KNeighborsClassifier(n_neighbors = 13)\n",
    "estimator.fit(X_train, y_train)\n",
    "label_predict = estimator.predict(X_test)\n",
    "print('The accuracy score of classification: %.9f'\n",
    "     %accuracy_score(y_test, label_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
